# -*- coding: utf-8 -*-
"""azure_demand_forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aCRYiKlC1gB-BlYZInmm3H5PXApOxVf7
"""

import pandas as pd
import numpy as np
from datetime import timedelta

np.random.seed(42)

# 2 Years Monthly Data
date_range = pd.date_range(start="2023-01-01",
                           end="2024-12-01",
                           freq="MS")

regions = ["US-East", "EU-Central"]
service_types = ["Compute", "Storage"]

azure_data = []

for date in date_range:
    month = date.month

    for region in regions:
        for service in service_types:

            #Varying Time
            random_time = timedelta(
                hours=np.random.randint(0, 24),
                minutes=np.random.randint(0, 60),
                seconds=np.random.randint(0, 60)
            )

            full_timestamp = date + random_time

            # Seasonal effect
            seasonal_factor = 1.3 if month in [6,7,8,11,12] else 1.0

            base_usage = 5000 if service == "Compute" else 3000
            usage_units = base_usage * seasonal_factor * np.random.uniform(0.85, 1.15)

            provisioned_capacity = usage_units * np.random.uniform(1.1, 1.35)

            cost_rate = 0.12 if service == "Compute" else 0.05
            cost_usd = usage_units * cost_rate

            azure_data.append([

                full_timestamp,
                region,
                service,
                round(usage_units, 2),
                round(provisioned_capacity, 2),
                round(cost_usd, 2)
            ])

azure_df = pd.DataFrame(azure_data, columns=[
    "time_stamp",
    "region",
    "service_type",
    "usage_units",
    "provisioned_capacity",
    "cost_usd"
])

print("Azure Dataset Shape:", azure_df.shape)
azure_df.head()

external_data = []

for index, row in azure_df.iterrows():

    market_demand_index = np.random.uniform(75, 120)
    customer_growth = np.random.uniform(2, 10)
    regional_growth = np.random.uniform(2.5, 6.5)

    external_data.append([
        row["time_stamp"],
        row["region"],
        round(market_demand_index, 2),
        round(customer_growth, 2),
        round(regional_growth, 2)
    ])

external_df = pd.DataFrame(external_data, columns=[
    "time_stamp",
    "region",
    "market_demand_index",
    "customer_growth",
    "regional_growth"
])

print("External Dataset Shape:", external_df.shape)
display(external_df.head())

df = pd.merge(
    azure_df,
    external_df,
    on=["time_stamp", "region"],
    how="left"
)

print("Merged Dataset Shape:", df.shape)
df.head()

# missing values
df.loc[df.sample(frac=0.02).index, "usage_units"] = np.nan
df.loc[df.sample(frac=0.02).index, "market_demand_index"] = np.nan

print("Missing Values Before Cleaning:")
print(df.isnull().sum())

# Sort for time-series consistency
df.sort_values(by=["region", "service_type", "time_stamp"], inplace=True)

df["usage_units"] = df.groupby(["region", "service_type"])["usage_units"].transform(lambda x: x.ffill())

# Filling market index with mean
df["market_demand_index"] = df["market_demand_index"].fillna(
    df["market_demand_index"].mean()
)

print("\nMissing Values After Cleaning:")
print(df.isnull().sum())

df["time_stamp"] = pd.to_datetime(df["time_stamp"])

numeric_cols = df.select_dtypes(include=np.number).columns
df[numeric_cols] = df[numeric_cols].astype(float)

print("\nDataset Info:")
print(df.info())

import plotly.express as px
region_usage = df.groupby(
    ["time_stamp", "region"]
)["usage_units"].sum().reset_index()

fig = px.line(
    region_usage,
    x="time_stamp",
    y="usage_units",
    color="region",
    title="Regional Usage Trends"
)

fig.show()